{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install efficientnet_pytorch\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ttach\n",
    "\n",
    "import ttach as tta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = \"cp3_231208_1556\"\n",
    "test_epoch = 7\n",
    "test_model_path = '/kaggle/input/trained-model'\n",
    "test_dataset_path = '/kaggle/input/image-classification2023-2nd/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "test_batch_size = 256\n",
    "epoch_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = v2.Compose([\n",
    "    v2.CenterCrop((240, 240)),\n",
    "    # v2.Lambda(lambda img:v2.functional.adjust_brightness(img, 1.2)),\n",
    "    v2.RandomRotation(degrees=(0, 30)), # 경진대회 종료 후 확인\n",
    "    v2.Lambda(lambda img:v2.functional.adjust_contrast(img, 1.2)),\n",
    "    v2.Lambda(lambda img:v2.functional.adjust_saturation(img, 1.2)),\n",
    "    v2.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [\n",
    "    '/kaggle/working/csv',\n",
    "    '/kaggle/working/save_state_dict',\n",
    "    '/kaggle/working/save_dict',\n",
    "]\n",
    "\n",
    "for dir_path in directories:\n",
    "    os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# 제너레이터 시드값 고정\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b1', \n",
    "                                    num_classes=2) \n",
    "\n",
    "# 장비 할당\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.df.iloc[idx, 0] \n",
    "        image_path = f'/kaggle/input/image-classification2023-2nd/test/{image_name}'\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/image-classification2023-2nd/sample_submission.csv')\n",
    "\n",
    "datasets_test = CustomDataset(test_df, transform=test_transforms)\n",
    "\n",
    "loader_test = DataLoader(dataset=datasets_test, batch_size=test_batch_size, \n",
    "                         shuffle=False, worker_init_fn=seed_worker,\n",
    "                         generator=g, num_workers=0)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 변환 정의\n",
    "tta_transforms = tta.Compose([\n",
    "    tta.HorizontalFlip(),\n",
    "    tta.Rotate90(angles=[0, 90, 180, 270]),\n",
    "    tta.Multiply(factors=[0.9, 1, 1.1]),   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 가중치 불러오기\n",
    "model.load_state_dict(torch.load(f'/kaggle/working/save_dict/{test_name}_{str(test_epoch)}.pth'))\n",
    "\n",
    "# TTA 모델 생성\n",
    "tta_model = tta.ClassificationTTAWrapper(model, tta_transforms)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for images in tqdm(loader_test):  # 레이블은 사용하지 않음\n",
    "    images = images.to(device)  # 장비 할당\n",
    "    with torch.no_grad():\n",
    "        outputs = tta_model(images)\n",
    "        prediction = outputs.argmax(dim=1).cpu().numpy()\n",
    "        predictions.extend(prediction)\n",
    "        \n",
    "test_df['label'] = predictions\n",
    "\n",
    "test_df.to_csv(f'/kagle/working/csv/{test_name}_{test_epoch}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
